name: catalyst-cv
# <- standard block end ->
on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - develop
      - master


jobs:
  build:
    name: dl-cpu-cv
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      # max-parallel: 6
      matrix:
        os: [ubuntu-18.04, macOS-10.15]  # windows-2019,
        python-version: [3.6, 3.7, 3.8]
        requirements: ['minimal', 'latest']
        exclude:
          # pypi problems
          - python-version: 3.8
            requirements: 'minimal'
          - python-version: 3.7
            requirements: 'minimal'
          # pickle problems
          - python-version: 3.8
            os: macOS-10.15
          - python-version: 3.6
            os: macOS-10.15

    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v2

      - name: set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      # https://github.com/pytorch/pytorch/issues/20030
      - name: Setup macOS
        if: startsWith(runner.os, 'macOS')
        run: |
          brew install libomp
          brew install gnu-sed

      - name: set minimal dependencies
        if: matrix.requirements == 'minimal'
        run: |
          python -c "req = open('./requirements/requirements.txt').read().replace('>', '=') ; open('./requirements/requirements.txt', 'w').write(req)"
          python -c "req = open('./requirements/requirements-cv.txt').read().replace('>', '=') ; open('./requirements/requirements-cv.txt', 'w').write(req)"
          python -c "req = open('./requirements/requirements-nlp.txt').read().replace('>', '=') ; open('./requirements/requirements-nlp.txt', 'w').write(req)"

      # https://github.com/actions/cache/blob/master/examples.md
      # Note: This uses an internal pip API and may not always work
      # https://github.com/actions/cache/blob/master/examples.md#multiple-oss-in-a-workflow
      - name: get pip cache dir
        id: pip-cache
        run: |
          python -c "from pip._internal.locations import USER_CACHE_DIR; print('::set-output name=dir::' + USER_CACHE_DIR)"

      - name: pip cache
        uses: actions/cache@v2
        with:
          path: ${{ steps.pip-cache.outputs.dir }}
          key: ${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requirements }}-pip-${{ hashFiles('./requirements/requirements.txt') }}-${{ hashFiles('./tests/requirements.txt') }}-${{ hashFiles('./requirements/requirements-cv.txt') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.python-version }}-${{ matrix.requirements }}-pip-

      - name: install dependencies
        run: |
          # python -m pip install --upgrade --user pip
          pip install -r ./requirements/requirements.txt -r ./tests/requirements.txt -r ./requirements/requirements-cv.txt --quiet --find-links https://download.pytorch.org/whl/cpu/torch_stable.html --upgrade-strategy only-if-needed
          python --version
          pip --version
          pip list
        shell: bash
# <- standard block end ->

      # https://github.com/actions/cache
      - name: cache data - isbi
        id: cache-isbi
        uses: actions/cache@v2
        with:
          path: data/isbi
          key: isbi-data

      - name: data - isbi
        if: steps.cache-isbi.outputs.cache-hit != 'true'
        run: |
          mkdir -p data
          bash bin/scripts/download-gdrive 1N82zh0kzmnzqRvUyMgVOGsCoS1kHf3RP ./data/isbi.tar.gz
          tar -xf ./data/isbi.tar.gz -C ./data/

      - name: cache data - MNIST
        id: cache-mnist
        uses: actions/cache@v2
        with:
          path: data/MNIST
          key: MNIST-data

      - name: data - MNIST
        if: steps.cache-mnist.outputs.cache-hit != 'true'
        run: |
          mkdir -p data
          bash bin/scripts/download-gdrive 1D_sz7bQSSBDQKNUMSEniXHc9_jHP4EXO ./data/MNIST.zip
          unzip -qqo ./data/MNIST.zip -d ./data

      - name: cache data - segmentation
        id: cache-segmentation
        uses: actions/cache@v2
        with:
          path: data/segmentation_data
          key: segmentation-data

      - name: data - segmentation
        if: steps.cache-segmentation.outputs.cache-hit != 'true'
        run: |
          mkdir -p data
          bash bin/scripts/download-gdrive 1iYaNijLmzsrMlAdMoUEhhJuo-5bkeAuj ./data/segmentation_data.zip
          unzip -qqo ./data/segmentation_data.zip -d ./data

      - name: remove incompatible tests
        if: matrix.requirements == 'minimal'
        run: |
          # kornia has requirement torch>=1.5.0, while in minimal tests torch==1.1.0 is used
          rm -rf ./tests/_tests_scripts/cv_z_kornia.py

      - name: check examples
        env:
          REQUIREMENTS: ${{ matrix.requirements }}
        run: |
          (set -e; for f in ./bin/tests/check_dl_core*.sh; do USE_APEX="0" CUDA_VISIBLE_DEVICES="" bash "$f"; done)
          (set -e; for f in ./bin/tests/check_dl_cv*.sh; do USE_APEX="0" CUDA_VISIBLE_DEVICES="" bash "$f"; done)
