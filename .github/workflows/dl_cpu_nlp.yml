#name: catalyst-nlp
## <- standard block end ->
#on:
#  push:
#    branches:
#      - master
#  pull_request:
#    branches:
#      - develop
#      - master
#
#
#jobs:
#  build:
#    name: dl-cpu-nlp
#    runs-on: ${{ matrix.os }}
#    strategy:
#      fail-fast: false
#      # max-parallel: 6
#      matrix:
#        os: [ubuntu-18.04] # , windows-2019, macOS-10.15]
#        python-version: [3.6] #, 3.7, 3.8]
#        requires: ['minimal', 'latest']
##        exclude:
##          # excludes node 4 on macOS
##          - python-version: 3.8
##            requires: 'minimal'
#    # Timeout: 4
#    timeout-minutes: 30
#    steps:
#      - uses: actions/checkout@v2
#
#      - name: set up Python ${{ matrix.python-version }}
#        uses: actions/setup-python@v1
#        with:
#          python-version: ${{ matrix.python-version }}
#
#      - name: set minimal dependencies
#        if: matrix.requires == 'minimal'
#        run: |
#          python -c "req = open('./requirements/requirements.txt').read().replace('>', '=') ; open('./requirements/requirements.txt', 'w').write(req)"
#          python -c "req = open('./requirements/requirements-cv.txt').read().replace('>', '=') ; open('./requirements/requirements-cv.txt', 'w').write(req)"
#          python -c "req = open('./requirements/requirements-nlp.txt').read().replace('>', '=') ; open('./requirements/requirements-nlp.txt', 'w').write(req)"
#
#      - name: setup ubuntu
#        run: |
#          python -c "from pip._internal.locations import USER_CACHE_DIR; print('::set-output name=dir::' + USER_CACHE_DIR)"
#
#      # https://github.com/actions/cache/blob/master/examples.md
#      # Note: This uses an internal pip API and may not always work
#      # https://github.com/actions/cache/blob/master/examples.md#multiple-oss-in-a-workflow
#      - name: get pip cache
#        id: pip-cache
#        run: |
#          python -c "from pip._internal.locations import USER_CACHE_DIR; print('::set-output name=dir::' + USER_CACHE_DIR)"
#
#      - name: cache pip
#        uses: actions/cache@v1
#        with:
#          path: ${{ steps.pip-cache.outputs.dir }}
#          key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('./requirements/requirements.txt') }}-${{ hashFiles('./requirements/requirements-nlp.txt') }}-${{ hashFiles('./tests/requirements.txt') }}
#          restore-keys: |
#            ${{ runner.os }}-${{ matrix.python-version }}-pip-
#
#      - name: install dependencies
#        run: |
#          # python -m pip install --upgrade --user pip
#          pip install -r ./requirements/requirements.txt -r ./requirements/requirements-nlp.txt -r ./tests/requirements.txt
#          python --version
#          pip --version
#          pip list
#        shell: bash
## <- standard block end ->
#
#      # https://github.com/actions/cache
#      - name: cache data - isbi
#        uses: actions/cache@v1
#        with:
#          path: data # This path is specific to Ubuntu
#          # Look to see if there is a cache hit for the corresponding requirements file
#          key: isbi
#      - name: cache data - MNIST
#        uses: actions/cache@v1
#        with:
#          path: data # This path is specific to Ubuntu
#          # Look to see if there is a cache hit for the corresponding requirements file
#          key: MNIST
#
#      - name: check examples
#        run: |
#          rm -rf ./data
#          mkdir -p data
#          bash bin/scripts/download-gdrive 1N82zh0kzmnzqRvUyMgVOGsCoS1kHf3RP ./data/isbi.tar.gz
#          tar -xf ./data/isbi.tar.gz -C ./data/
#          bash bin/scripts/download-gdrive 1D_sz7bQSSBDQKNUMSEniXHc9_jHP4EXO ./data/MNIST.zip
#          unzip -qqo ./data/MNIST.zip -d ./data
#          (set -e; for f in ./bin/tests/check_dl_core*.sh; do USE_APEX="0" CUDA_VISIBLE_DEVICES="" bash "$f"; done)
#          (set -e; for f in ./bin/tests/check_dl_nlp*.sh; do USE_APEX="0" CUDA_VISIBLE_DEVICES="" bash "$f"; done)
