{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "completed-input",
   "metadata": {},
   "source": [
    "### For using DALI recommended use [NGC PyTorch container](https://ngc.nvidia.com/catalog/containers/nvidia:pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "backed-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali as dali\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator, LastBatchPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hybrid-southeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.29.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dali.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-causing",
   "metadata": {},
   "source": [
    "### To get test data you need to use [DALI extra](https://github.com/NVIDIA/DALI_extra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "creative-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "data_paths = {\n",
    "    'train': 'DALI_extra/db/MNIST/training/',\n",
    "    'valid': 'DALI_extra/db/MNIST/testing/',\n",
    "}\n",
    "\n",
    "class MNISTPipeline(Pipeline):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'train',\n",
    "        batch_size: int = 16,\n",
    "        num_threads: int = 4,\n",
    "        device_id: int = 0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            batch_size=batch_size,\n",
    "            num_threads=num_threads,\n",
    "            device_id=device_id\n",
    "        )\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.input = ops.Caffe2Reader(path=data_paths[mode], random_shuffle=True, name='Reader')\n",
    "        self.decode = ops.ImageDecoder(device = 'mixed', output_type = types.GRAY)\n",
    "        self.cmn = ops.CropMirrorNormalize(\n",
    "            device=\"gpu\",\n",
    "            dtype=types.FLOAT,\n",
    "            std=[0.3081 * 255],\n",
    "            mean=[0.1307 * 255],\n",
    "            output_layout=types.NCHW,\n",
    "        )\n",
    "    \n",
    "    def define_graph(self):\n",
    "        jpegs, labels = self.input()\n",
    "        images = self.decode(jpegs)\n",
    "        images = self.cmn(images)\n",
    "        return images, labels.gpu()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 60000 if self.mode == 'train' else 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranging-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customizing DALI loader for using in catalyst.\n",
    "class DALILoader(DataLoader):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = 'train',\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.pipeline = MNISTPipeline(mode=mode, batch_size=batch_size, num_threads=num_workers)\n",
    "        self.pipeline.build()\n",
    "        \n",
    "        self.loader = DALIGenericIterator(\n",
    "            pipelines=self.pipeline,\n",
    "            output_map=['features', 'targets'],\n",
    "            size=len(self.pipeline),\n",
    "            auto_reset=True,\n",
    "            last_batch_policy=LastBatchPolicy.PARTIAL,\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return ({'features': batch[0][\"features\"], 'targets': batch[0][\"targets\"].squeeze().long()} for batch in self.loader)\n",
    "    \n",
    "    def sampler(self):\n",
    "        return None\n",
    "    \n",
    "    def batch_sampler(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artificial-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from catalyst import dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "leading-supervisor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.\n",
      "  _iterator_deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 10))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "loaders = {\n",
    "    'train': DALILoader(mode='train', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS),\n",
    "    'valid': DALILoader(mode='valid', batch_size=BATCH_SIZE, num_workers=NUM_WORKERS),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "boolean-directive",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314b460925044485ada4fab86d46a916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='1/1 * Epoch (train)'), FloatProgress(value=0.0, max=1875.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "train (1/1) accuracy: 0.8600333333333344 | accuracy/std: 0.06956738615119247 | accuracy01: 0.8600333333333344 | accuracy01/std: 0.06956738615119247 | accuracy03: 0.9711833333333335 | accuracy03/std: 0.03746301216102217 | accuracy05: 0.9904 | accuracy05/std: 0.021567091111003207 | auc: 0.9589463472366333 | auc/_macro: 0.9589463472366333 | auc/_micro: 0.9643569778395064 | auc/_weighted: 0.9597810506820679 | auc/class_00: 0.9915761351585388 | auc/class_01: 0.9921147227287292 | auc/class_02: 0.9578843116760254 | auc/class_03: 0.948928952217102 | auc/class_04: 0.9723076224327087 | auc/class_05: 0.9283470511436462 | auc/class_06: 0.9845988154411316 | auc/class_07: 0.9818652272224426 | auc/class_08: 0.9049604535102844 | auc/class_09: 0.9268798232078552 | f1/_macro: 0.8582526362879174 | f1/_micro: 0.8600283333624017 | f1/_weighted: 0.8599756467422307 | f1/class_00: 0.9331256991150798 | f1/class_01: 0.9339300448150216 | f1/class_02: 0.848520581821531 | f1/class_03: 0.8315052041164961 | f1/class_04: 0.8651692994283214 | f1/class_05: 0.7858016901246627 | f1/class_06: 0.909700211616619 | f1/class_07: 0.8825402516070081 | f1/class_08: 0.7901226888195925 | f1/class_09: 0.8021106914148414 | loss: 1.303020315342241 | loss/mean: 1.303020315342241 | loss/std: 0.8711894802518808 | lr: 0.02 | momentum: 0.9 | precision/_macro: 0.8582543978503923 | precision/_micro: 0.8600333333333333 | precision/_weighted: 0.8599321325778112 | precision/class_00: 0.9332882958959635 | precision/class_01: 0.931660516605166 | precision/class_02: 0.849453322119428 | precision/class_03: 0.8323255433894428 | precision/class_04: 0.863698396451723 | precision/class_05: 0.7872616182188483 | precision/class_06: 0.9094747508866745 | precision/class_07: 0.8817718291905672 | precision/class_08: 0.7923685115159849 | precision/class_09: 0.8012411942301241 | recall/_macro: 0.8582649997496838 | recall/_micro: 0.8600333333333333 | recall/_weighted: 0.8600333333333333 | recall/class_00: 0.932973155495526 | recall/class_01: 0.936220706021952 | recall/class_02: 0.8475998657267539 | recall/class_03: 0.8306964606100147 | recall/class_04: 0.8666552550496405 | recall/class_05: 0.7843571296808707 | recall/class_06: 0.9099357891179453 | recall/class_07: 0.8833200319233838 | recall/class_08: 0.7878995043582293 | recall/class_09: 0.8029920995125231 | support/class_00: 5923.0 | support/class_01: 6742.0 | support/class_02: 5958.0 | support/class_03: 6131.0 | support/class_04: 5842.0 | support/class_05: 5421.0 | support/class_06: 5918.0 | support/class_07: 6265.0 | support/class_08: 5851.0 | support/class_09: 5949.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056176aae1844cf4bba2fd8d256e4e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='1/1 * Epoch (valid)'), FloatProgress(value=0.0, max=313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "valid (1/1) accuracy: 0.8767000000000005 | accuracy/std: 0.05568253814711977 | accuracy01: 0.8767000000000005 | accuracy01/std: 0.05568253814711977 | accuracy03: 0.9773 | accuracy03/std: 0.02544159443652752 | accuracy05: 0.9931999999999997 | accuracy05/std: 0.014492446415298916 | auc: 0.9759805798530579 | auc/_macro: 0.9759805798530579 | auc/_micro: 0.9729051977777778 | auc/_weighted: 0.9763350486755371 | auc/class_00: 0.9960879683494568 | auc/class_01: 0.9964075684547424 | auc/class_02: 0.9756388068199158 | auc/class_03: 0.975641667842865 | auc/class_04: 0.9830971956253052 | auc/class_05: 0.9661995768547058 | auc/class_06: 0.9908614754676819 | auc/class_07: 0.9855570793151855 | auc/class_08: 0.9420429468154907 | auc/class_09: 0.9482711553573608 | f1/_macro: 0.8759836176129701 | f1/_micro: 0.8766950000285159 | f1/_weighted: 0.8775865870995762 | f1/class_00: 0.9440820901827106 | f1/class_01: 0.9570668515130788 | f1/class_02: 0.8349113495850965 | f1/class_03: 0.8058284587100432 | f1/class_04: 0.8999950026536165 | f1/class_05: 0.8004907184500706 | f1/class_06: 0.909790258950871 | f1/class_07: 0.9051758408117714 | f1/class_08: 0.8248977580642023 | f1/class_09: 0.8775978472082397 | loss: 1.400999232346751 | loss/mean: 1.400999232346751 | loss/std: 0.9728488953666629 | lr: 0.02 | momentum: 0.9 | precision/_macro: 0.8870415693015813 | precision/_micro: 0.8767 | precision/_weighted: 0.8873025788194351 | precision/class_00: 0.9164265129682997 | precision/class_01: 0.9823747680890538 | precision/class_02: 0.7828668363019509 | precision/class_03: 0.6956834532374101 | precision/class_04: 0.9211087420042644 | precision/class_05: 0.8947368421052632 | precision/class_06: 0.9681978798586572 | precision/class_07: 0.9096267190569745 | precision/class_08: 0.8993939393939394 | precision/class_09: 0.9 | recall/_macro: 0.873928306640072 | recall/_micro: 0.8767 | recall/_weighted: 0.8767 | recall/class_00: 0.9734693877551021 | recall/class_01: 0.9330396475770926 | recall/class_02: 0.8943798449612403 | recall/class_03: 0.9574257425742574 | recall/class_04: 0.879837067209776 | recall/class_05: 0.7242152466367713 | recall/class_06: 0.8580375782881002 | recall/class_07: 0.9007782101167315 | recall/class_08: 0.7618069815195072 | recall/class_09: 0.8562933597621407 | support/class_00: 980.0 | support/class_01: 1135.0 | support/class_02: 1032.0 | support/class_03: 1010.0 | support/class_04: 982.0 | support/class_05: 892.0 | support/class_06: 958.0 | support/class_07: 1028.0 | support/class_08: 974.0 | support/class_09: 1009.0\n",
      "* Epoch (1/1) \n",
      "Top best models:\n",
      "logs/checkpoints/train.1.pth\t1.4010\n"
     ]
    }
   ],
   "source": [
    "runner = dl.SupervisedRunner()\n",
    "\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    num_epochs=1,\n",
    "    logdir=\"./logs\",\n",
    "    valid_loader=\"valid\",\n",
    "    valid_metric=\"loss\",\n",
    "    minimize_valid_metric=True,\n",
    "    verbose=True,\n",
    "    callbacks=[\n",
    "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", num_classes=10),\n",
    "        dl.PrecisionRecallF1SupportCallback(\n",
    "            input_key=\"logits\", target_key=\"targets\", num_classes=10\n",
    "        ),\n",
    "        dl.AUCCallback(input_key=\"logits\", target_key=\"targets\"),\n",
    "        # catalyst[ml] required ``pip install catalyst[ml]``\n",
    "        dl.ConfusionMatrixCallback(\n",
    "            input_key=\"logits\", target_key=\"targets\", num_classes=10\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
