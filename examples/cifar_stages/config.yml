# For detailed comments on this configuration file refer to configs/config-description-eng.yml

shared:
  dataset_root: &dataset_root "./data"
  seed: &seed 42
  valid_loader: &valid_loader valid
  valid_metric: &valid_metric accuracy01
  minimize_valid_metric: False


args:
  expdir: "cifar_stages"
  logdir: &logdir "./logs/cifar_stages"
  seed: *seed
  distributed: False
  apex: False
  amp: False
  verbose: False
  timeit: False
  check: False
  overfit: False
  deterministic: False
  benchmark: False

runner:
#  _target_: SupervisedConfigRunner
  input_key: &model_input "features"
  output_key: &model_output "logits"
  target_key: &model_target "targets"
  loss_key: &model_loss "loss"

# TODO: add `_target_` support
engine:
  engine: "cpu"
#  _target_: DeviceEngine
#  device: "cpu"

loggers:
  console:
    _target_: ConsoleLogger
  tensorboard:
    _target_: TensorboardLogger
    logdir: *logdir

model:
  _target_: SimpleNet

stages:
  train:
    num_epochs: 10

    loaders:
      batch_size: 32
      num_workers: 1

#      datasets:
#        train:
#          _target_: MNIST
#          root: *dataset_root
#          train: True
#          download: True
#        valid:
#          _target_: MNIST
#          root: *dataset_root
#          train: False
#          download: True
#
#      samplers:
#        train:
#          _target_: MiniEpochSampler
#          data_len: 50000
#          mini_epoch_len: 35000
#          drop_last: True
#          shuffle: per_epoch
#
#      transforms:
#        _target_: albumentations.Compose
#        transforms:
#          - _target_: albumentations.Normalize
#          - _target_: catalyst.ImageToTensor

    criterion:
      _target_: CrossEntropyLoss

    optimizer:
      _target_: Ralamb

    scheduler:
      _target_: MultiStepLR
      milestones: [ 8 ]
      gamma: 0.3

    callbacks:
      loss:
        _target_: CriterionCallback
        input_key: *model_output
        target_key: *model_target
        metric_key: *model_loss
      optimizer:
        _target_: OptimizerCallback
        metric_key: *model_loss
      accuracy:
        _target_: AccuracyCallback
        input_key: *model_output
        target_key: *model_target
        topk_args: [ 1, 3, 5 ]
      scheduler:
        _target_: SchedulerCallback
        loader_key: *valid_loader
        metric_key: *valid_metric
      saver:
        _target_: CheckpointCallback
        logdir: *logdir
        loader_key: *valid_loader
        metric_key: *valid_metric
        minimize: True
      verbose:
        _target_: TqdmCallback

  tune:
    num_epochs: 6

    criterion:
      _target_: CrossEntropyLoss

    optimizer:
      _target_: Ralamb
#      lr_linear_scaling:
#        lr: 0.0001
#        base_batch_size: 64
#      weight_decay: 0.0001
#      no_bias_weight_decay: False

    scheduler:
      _target_: MultiStepLR
      milestones: [ 3 ]
      gamma: 0.3

    callbacks:
      loss:
        _target_: CriterionCallback
        input_key: *model_output
        target_key: *model_target
        metric_key: *model_loss
      optimizer:
        _target_: OptimizerCallback
        metric_key: *model_loss
      accuracy:
        _target_: AccuracyCallback
        input_key: *model_output
        target_key: *model_target
        topk_args: [ 1, 3, 5 ]
      scheduler:
        _target_: SchedulerCallback
        loader_key: *valid_loader
        metric_key: *valid_metric
      saver:
        _target_: CheckpointCallback
        logdir: *logdir
        loader_key: *valid_loader
        metric_key: *valid_metric
        minimize: True
      verbose:
        _target_: TqdmCallback


