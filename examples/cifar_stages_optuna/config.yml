# Refer to configs/config-description-eng.yml
# for detailed comments on this configuration file

model_params:
  model: SimpleNet
  num_filters1: "int(trial.suggest_loguniform('num_filters1', 4, 32))"
  num_filters2: "int(trial.suggest_loguniform('num_filters2', 4, 32))"
  num_hiddens1: "int(trial.suggest_loguniform('num_hiddens1', 32, 128))"
  num_hiddens2: "int(trial.suggest_loguniform('num_hiddens2', 32, 128))"


runner_params:
  runner: SupervisedRunner
  input_key: image


args:
  expdir: "cifar_stages_optuna"
  baselogdir: "./logs/cifar_stages_optuna"


stages:

  data_params:
    batch_size: 64
    num_workers: 1

  transform_params:
    transform: albumentations.Compose
    transforms:
      - transform: albumentations.Normalize
      - transform: catalyst.ImageToTensor

  stage_params:
    num_epochs: 3
    main_metric: &reduced_metric accuracy01
    minimize_metric: False

  criterion_params:
    criterion: CrossEntropyLoss

  scheduler_params:
    scheduler: MultiStepLR
    milestones: [10]
    gamma: 0.3

  callbacks_params:
    loss:
      callback: CriterionCallback
    optimizer:
      callback: OptimizerCallback
    accuracy:
      callback: AccuracyCallback
      accuracy_args: [1, 3, 5]
    scheduler:
      callback: SchedulerCallback
      reduced_metric: *reduced_metric
    saver:
      callback: CheckpointCallback

  stage1:
    optimizer_params:
      optimizer: Ralamb

      layerwise_params:
        conv1.*:
          lr: 0.001
          weight_decay: 0.0003
        conv.*:
          lr: 0.002

      lr_linear_scaling:
        lr: 0.001
        base_batch_size: 64
      weight_decay: 0.0001
      no_bias_weight_decay: True # removes `weight_decay` for model's biases

  # tune
#  stage2:
#    stage_params:
#      num_epochs: 3
#
#    optimizer_params:
#      load_from_previous_stage: True
#      optimizer: Ralamb
#      lr_linear_scaling:
#        lr: 0.0001
#        base_batch_size: 64
#      weight_decay: 0.0001
#      no_bias_weight_decay: False
