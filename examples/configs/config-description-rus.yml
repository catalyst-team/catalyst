# На этом уровне, могут находится любые дополнительные параметры, помимо обязательных ключевых слов
shared:  # Пример
  key: &key value
  key2: &key2 value2

args:  # REQUIRED KEYWORD, различные аргументы для Catalyst
  expdir: "src"  # REQUIRED KEYWORD, путь до вашего эксперимента, с файлом `__init__`, в котором импортируется Experiment, Runner, и, опционально, регистрируются все дополнительные сущности: model, callback, criterion, etc
  logdir: /path/to/logdir  # KEYWORD путь в который будут сохранятся логи (может быть пустым, если передан baselogdir)
  baselogdir: /path/to/baselogdir  # KEYWORD необязательный аргумент -- путь для корня с логами (если указан он, но не указан logdir, тогда логдир будет получен, как `{baselogdir}/{ConfigExperiment._get_logdir(config)}`)
  seed: 42  # KEYWORD сид обучения для PyTorch, Numpy, Python и Tensorflow. По умолчанию равен 42
  deterministic: True  # KEYWORD нужно ли использовать deterministic CuDNN (по умолчанию True)
  benchmark: True  # KEYWORD нужно ли использовать CuDNN benchmark
  verbose: False  # KEYWORD нужно ли выводить на консоль информацию об обучении (по умолчанию False)
  check: False  # KEYWORD, если True, то Catalyst делает только 3 эпохи (чтобы проверить работоспособность пайплайна, по умолчанию False)

runner:  # REQUIRED KEYWORD, параметры для инициализации Runner
  # Например для SupervisedRunner
  _target_: SupervisedRunner  # REQUIRED KEYWORD Имя класса. Сам класс будет сконструирован в registry по этому имени
  # на этом уровне могут лежать параметры для __init__ данного runner, например
  input_key: "features"  # Пример
  output_key: null  # Пример

engine:  # REQUIRED KEYWORD, параметры для инициализации Engine
  _target_: DeviceEngine  # REQUIRED KEYWORD Имя класса. Сам класс будет сконструирован в registry по этому имени
  # на этом уровне могут лежать параметры для __init__ данного engine, например
  device: "cpu"

model:  # REQUIRED KEYWORD, параметры модели (моделей)
  _key_value: False  # KEYWORD, если True, то моделей может быть несколько и тогда их нужно обернуть еще в key-value

  _target_: ModelName  # REQUIRED KEYWORD Имя класса. Сам класс будет сконструирован в registry по этому имени
  # на этом уровне могут лежать параметры для __init__ данной модели, например
  arch: resnet18  # благодаря этому ключу модель будет создана так `ModelName(arch=resnet18)`

stages:  # REQUIRED KEYWORD, словарь всех стадий Catalyst, для обучения и/или инфера. Содержат ключевые слова с параметрами, которые применятся ко всем стейджам, так и сами имена стейджей

  stage1:  # Все, что не ключевое слово, расценивается, как имя стейджа. Для тренировки в Catalyst требуется хотябы один стейдж. Имя может быть произвольным
    num_epochs: 10  # KEYWORD, Количество эпох в этом стейдже

    laoders: &loaders  # REQUIRED KEYWORD
      # kwargs для `runner.get_loaders(...)` в этом стейдже
      batch_size: 1  # KEYWORD, размер батча для всех стейджей
      num_workers: 1  # KEYWORD, количество параллельных процессов для DataLoader
      drop_last: False  # KEYWORD, параметр для DataLoader (по умолчанию False)
      loaders_params:  # KEYWORD, словарь с дополнительными параметры для DataLoader. Аналогичным образом можно передавать параметры в Sampler через словарь samplers_params
        persistent_workers: True # KEYWORD, пример параметра. Полный список допустимых параметров можно найти в документации к torch.utils.data.DataLoader
      per_gpu_scaling: False  # KEYWORD, если True, то увеличивает батчсайз и количество воркеров пропорционально количиству видеокарт (для distributed увеличивает только батчсайз)

      # kwargs для `runner.get_datasets(...)` в этом стейдже
      some_extra_key: "some_extra_value"

    criterion: # REQUIRED KEYWORD, параметры для лосс-функции
      _key_value: False  # KEYWORD, если True, то лосс-функций может быть несколько и тогда их нужно обернуть еще в key-value

      _target_: BCEWithLogitsLoss  # REQUIRED KEYWORD, имя лосс функции
      # на этом уровне могут лежать параметры для __init__ данной лосс-функции, например
      reduction: sum

    optimizer: # REQUIRED KEYWORD, параметры для оптимизатора
      _key_value: False  # KEYWORD, если True, то оптимизаторов может быть несколько и тогда их нужно обернуть еще в key-value
      layerwise_params: # KEYWORD, параметры оптимайзера для разных слоев сети, опционально
        conv1.*: # регулярное выражение с именем слоя
          lr: 0.001
          weight_decay: 0.0003
        encoder.conv.*:
          lr: 0.002
      no_bias_weight_decay: True  # KEYWORD нужно ли убрать weight decay из bias параметров сети (по умолчанию True)
      lr_linear_scaling: # KEYWORD, параметры для линейного скейлинга lr
        lr: 0.001
        base_batch_size: 64  # KEYWORD, размер базового батча

      _target_: Adam  # REQUIRED KEYWORD, имя оптимизатора
      # на этом уровне могут лежать параметры для __init__ данного оптимизатора, например
      lr: 0.003
      weight_decay: 0.0001

    scheduler: # REQUIRED KEYWORD, параметры для lr-scheduler
      _key_value: False  # KEYWORD, если True, то lr-scheduler может быть несколько и тогда их нужно обернуть еще в key-value

      _target_: StepLR  # REQUIRED KEYWORD, имя lr-scheduler
      # на этом уровне могут лежать параметры для __init__ данного lr-scheduler, например
      step_size: 10
      gamma: 0.3

    callbacks:  &callbacks  # REQUIRED KEYWORD, самая важная часть, тут записываются все коллбеки для данного стейджа
    # коллбеки записываются через key-value
      loss:
        _target_: CriterionCallback  # KEYWORD имя коллбека
      optimizer:
        _target_: OptimizerCallback
      scheduler:
        _target_: SchedulerCallback
        # для любого коллбека на этом уровне лежат его параметры
        loader_key: "valid"
        metric_key: "loss"
      saver:
        _target_: CheckpointCallback
        save_n_best: 3

  finetune:  # Пример второго стейджа обучения, тут мы можем изменить наши параметры
    num_epochs: 3

    loaders: *loaders

    criterion: # Пример, переопределенного критерия
      _target_: CrossEntropyLoss

    optimizer:  # Пример, переопределенного оптимизатора
      _target_: Ralamb

    scheduler:
      _target_: MultiStepLR
      milestones: [ 2 ]
      gamma: 0.3

    callbacks: *callbacks

  # стейджей может быть любое количество
