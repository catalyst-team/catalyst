args:
  logdir: ./logs/_tests_rl_gym_ppo-continuous  #  change me
  expdir: ./examples/_tests_rl_gym

  vis: 0
  infer: 0  #  change me
  valid: 1  #  change me
  train: 1  #  change me

db:
  db: RedisDB
  port: 12000
  prefix: gym-ppo-continuous  # TODO: remove

environment:
  environment: GymWrapper
  env_name: PointEnv-v0

  history_len: 1
  frame_skip: 1
  reward_scale: 0.1

  observation_mean: [0.0, 0.0]
  observation_std: [2.0, 2.0]

agents:
  actor:
    agent: Actor

    state_net_params:  # state -> hidden representation
      observation_net_params:
        hiddens: [32]  # first hidden would be taken from state_shape
        layer_fn: Linear
        norm_fn: LayerNorm
        activation_fn: ReLU
        bias: false
      main_net_params:
        hiddens: [32, 32]
        layer_fn: Linear
        norm_fn: LayerNorm
        activation_fn: ReLU
        bias: false
    policy_head_params:  # hidden representation -> ~policy
      in_features: 32  # out features would be taken from action_shape
      policy_type: gauss
      out_activation: Tanh

  critic:
    agent: StateCritic

    state_net_params:  # state -> hidden representation
      observation_net_params:
        hiddens: [32]  # first hidden would be taken from state_shape
        layer_fn: Linear
        norm_fn: LayerNorm
        activation_fn: ReLU
        bias: false
      main_net_params:
        hiddens: [32, 32]
        layer_fn: Linear
        norm_fn: LayerNorm
        activation_fn: ReLU
        bias: false
    value_head_params:  # hidden representation -> ~policy
      in_features: 32  # out features would be taken from action_shape
      out_features: 1

algorithm:
  algorithm: PPO

  n_step: 1
  gamma: 0.99

  gae_lambda: 0.95
  clip_eps: 0.2
  entropy_reg_coefficient: 0.01

  actor_optimizer_params:
    optimizer: Adam
    lr: 0.0003
  critic_optimizer_params:
    optimizer: Adam
    lr: 0.0003

  actor_grad_clip_params:
    func: clip_grad_value_
    clip_value: 1.0

trainer:
  batch_size: 256              # transitions
  num_workers: 1
  num_mini_epochs: 10
  min_num_trajectories: 1000
  min_num_transitions: 10000

  save_period: 50              # epochs

sampler:
  exploration_params:
    - exploration: NoExploration
      probability: 1.0

  valid_seeds: [
    1608637542,
    1273642419,
    1935803228,
    787846414,
    996406378,
    1201263687,
    423734972,
    415968276,
    670094950,
    1914837113
  ]
