args:
  logdir: ./logs/_tests_rl_gym_ddpg-quantile  #  change me
  expdir: ./examples/_tests_rl_gym

  vis: 0
  infer: 0  #  change me
  valid: 1  #  change me
  train: 0  #  change me

db:
  db: RedisDB
  port: 12000
  prefix: gym-ddpg-quantile  # TODO: remove

environment:
  environment: GymEnvWrapper
  env_name: PointEnv-v0

  history_len: &history_len 1
  frame_skip: 1
  reward_scale: 0.1

  observation_mean: [0.0, 0.0]
  observation_std: [2.0, 2.0]

agents:
  actor:
    agent: Actor

    state_net_params:  # state -> hidden representation
      observation_net_params:
        _network_type: "linear"
        history_len: *history_len
        features: [32]  # first hidden would be taken from state_shape
        use_bias: false
        normalization: LayerNorm
        activation: ReLU
      main_net_params:
        features: [32]
        use_bias: false
        normalization: LayerNorm
        activation: ReLU
    policy_head_params:  # hidden representation -> ~policy
      in_features: 32    # out features would be taken from action_shape
      policy_type: null
      out_activation: Tanh

  critic:
    agent: StateActionCritic

    state_action_net_params:  # state -> hidden representation
      observation_net_params:
        _network_type: "linear"
        history_len: *history_len
        features: [32, 16]  # first hidden would be taken from state_shape
        use_bias: false
        normalization: LayerNorm
        activation: ReLU
      action_net_params:
        _network_type: "linear"
        features: [32, 16]  # first hidden would be taken from action_shape
        use_bias: false
        normalization: LayerNorm
        activation: ReLU
      main_net_params:
        features: [32]  # first hidden would be taken from action_shape
        use_bias: false
        normalization: LayerNorm
        activation: ReLU
    value_head_params:  # hidden representation -> value
      in_features: 32  # out features would be taken from action_shape
      out_features: 1

      distribution: quantile
      num_atoms: 21

algorithm:
  algorithm: DDPG

  n_step: 1
  gamma: 0.99
  actor_tau: 0.01
  critic_tau: 0.01

  critic_loss_params:
    criterion: HuberLoss
    clip_delta: 1.0

  actor_optimizer_params:
    optimizer: Adam
    lr: 0.001
  critic_optimizer_params:
    optimizer: Adam
    lr: 0.001

  actor_grad_clip_params:
    func: clip_grad_value_
    clip_value: 1.0

trainer:
  batch_size: 256              # transitions
  num_workers: 0
  epoch_len: 100               # batches

  replay_buffer_size: 1400000  # transitions
  min_num_transitions: 1332422 # transitions

  save_period: 50              # epochs
  weights_sync_period: 1       # epochs
  target_update_period: 1      # batches

sampler:
  weights_sync_period: 1

  exploration_params:
    - exploration: GaussNoise
      probability: 0.6
      sigma: 0.2

    - exploration: ParameterSpaceNoise
      probability: 0.2
      target_sigma: 0.2

    - exploration: NoExploration
      probability: 0.2

  valid_seeds: [
    1608637542,
    1273642419,
    1935803228,
    787846414,
    996406378,
    1201263687,
    423734972,
    415968276,
    670094950,
    1914837113,
    669991378,
    429389014,
    249467210,
    1972458954,
    1572714583,
    1433267572,
    434285667,
    613608295,
    893664919,
    648061058,
    88409749,
    242285876,
    2018247425,
    953477463,
    1427830251,
    1883569565,
    911989541,
    3344769,
    780932287,
    2114032571,
    787716372,
    504579232,
    1306710475,
    479546681,
    106328085,
    30349564,
    1855189739,
    99052376,
    1250819632,
    106406362,
    480404538,
    1717389822,
    599121577,
    200427519,
    1254751707,
    2034764475,
    1573512143,
    999745294,
    1958805693,
    389151677,
    1224821422,
    508464061,
    857592370,
    1642661739,
    61136438,
    2075460851,
    396917567,
    2004731384,
    199502978,
    1545932260,
    461901618,
    774414982,
    732395540,
    1934879560,
    279394470,
    56972561,
    1927948675,
    1899242072,
    1999874363,
    271820813,
    1324556529,
    1655351289,
    1308306184,
    68574553,
    419498548,
    991681409,
    791274835,
    1035196507,
    1890440558,
    787110843,
    524150214,
    472432043,
    2126768636,
    1431061255,
    147697582,
    744595490,
    1758017741,
    1679592528,
    1111451555,
    782698033,
    698027879,
    1096768899,
    1338788865,
    1826030589,
    86191493,
    893102645,
    200619113,
    290770691,
    793943861,
    134489564
  ]
