from typing import Any, Mapping, Union

import torch
import torch.nn as nn

from catalyst.engines.device import DeviceEngine


class DataParallelEngine(DeviceEngine):
    def __init__(self):
        super().__init__(f"cuda:{torch.cuda.current_device()}")
        self.device_count = torch.cuda.device_count()

    def __repr__(self) -> str:  # noqa: D105
        return f"DataParallelEngine(device_count={self.device_count})"

    def to_device(
        self, obj: Union[dict, torch.Tensor, nn.Module]
    ) -> Union[dict, torch.Tensor, nn.Module]:
        # fmt: off
        if isinstance(obj, dict):
            for k, v in obj.items():
                obj[k] = self.to_device(v)
        elif isinstance(obj, nn.Module) \
            and not isinstance(obj, nn.DataParallel):
            return nn.DataParallel(obj)
        else:
            return obj.to(self.device)
        # fmt: on

    def save_checkpoint(self, checkpoint: Mapping[str, Any], path: str):
        # TODO: method for unpacking torch.nn.DataParallel
        torch.save(checkpoint, path)
